{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/meituan/YOLOv6/blob/main/turtorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gBC7pTzB_ds"
   },
   "source": [
    "\n",
    "This is the official YOLOv6 notebook by MeiTuan, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
    "For more information please visit https://github.com/meituan/YOLOv6. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZVZhl5uCHka"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "YOLOv6 is a single-stage object detection framework dedicated to industrial applications, with hardware-friendly efficient design and high performance.\n",
    "\n",
    "YOLOv6 is composed of the following methods:\n",
    "\n",
    "Hardware-friendly Design for Backbone and Neck\n",
    "Efficient Decoupled Head with SIoU Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmqEfutmVHjs"
   },
   "source": [
    "# Setup\n",
    "Clone repo and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XA52vLvX06io",
    "outputId": "44505140-dd14-45f5-ccef-9deb599a1015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'YOLOv6'...\n",
      "remote: Enumerating objects: 1807, done.\u001b[K\n",
      "remote: Counting objects: 100% (821/821), done.\u001b[K\n",
      "remote: Compressing objects: 100% (226/226), done.\u001b[K\n",
      "remote: Total 1807 (delta 630), reused 697 (delta 592), pack-reused 986\u001b[K\n",
      "Receiving objects: 100% (1807/1807), 16.60 MiB | 5.25 MiB/s, done.\n",
      "Resolving deltas: 100% (994/994), done.\n",
      "/content/YOLOv6\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.13.1+cu113)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (4.64.0)\n",
      "Collecting addict>=2.4.0\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.8.0)\n",
      "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.0.4)\n",
      "Collecting onnx>=1.10.0\n",
      "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 21.0 MB/s \n",
      "\u001b[?25hCollecting onnx-simplifier>=0.3.6\n",
      "  Downloading onnx_simplifier-0.4.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 43.5 MB/s \n",
      "\u001b[?25hCollecting thop\n",
      "  Downloading thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch_quantization>=2.1.1 (from versions: 0.0.1.dev4, 0.0.1.dev5)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for pytorch_quantization>=2.1.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/meituan/YOLOv6.git\n",
    "%cd YOLOv6\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTJcbev3VO6i"
   },
   "source": [
    "# Inference\n",
    "First, download a pretrained model from the YOLOv6 [release](https://github.com/meituan/YOLOv6/releases).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "07dd33f907684614ba2e5bfadd48ff7f",
      "21a7574d0f3e4638880e61be9973475e",
      "0f610d79cba74702a5f0dca9712f6cdc",
      "0f4c5a98a3b84e3e9231b58c93e5959a",
      "a4ddf9969ed4474dad94e0a0d71b6239",
      "f31b5c163fe4410d985d6e66767e0524",
      "dbf3237c84a0431e90508105e56395c3",
      "e272cd27f3ff47ad98d6b011e07ab66d",
      "109524f358894009b0d3dfb1977e18b9",
      "bdad0e7d90954729a4a8fe10a7884f04",
      "8c6dc1b0b5014feb9c9ad7c2442e1727"
     ]
    },
    "id": "g2LM77g4i-TK",
    "outputId": "61d070d8-2cfe-4bc4-b998-af581c18296e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38.9M/38.9M [00:02<00:00, 16.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download a pretrained model\n",
    "import torch\n",
    "torch.hub.download_url_to_file('https://github.com/meituan/YOLOv6/releases/download/0.3.0/yolov6s.pt', 'yolov6s.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXrHMtniHtBG"
   },
   "source": [
    "Second, run inference with `tools/infer.py`, and saving results to `runs/inference`. Example inference sources are:\n",
    "\n",
    "```shell\n",
    "python tools/infer.py --weights yolov6s.pt --source img.jpg / imgdir\n",
    "                                yolov6n.pt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "9LUHrwwrWglt",
    "outputId": "fac2f29b-7a9b-4e45-cc15-b36b09dbe148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, classes=None, conf_thres=0.4, device='0', half=False, hide_conf=False, hide_labels=False, img_size=[640, 640], iou_thres=0.45, max_det=1000, name='exp', not_save_img=False, project='runs/inference', save_dir=None, save_txt=False, source='data/images/image1.jpg', view_img=False, webcam=False, webcam_addr='0', weights='yolov6s.pt', yaml='data/coco.yaml')\n",
      "Save directory already existed\n",
      "checkpoint yolov6s.pt not exist, try to downloaded it from github.\n",
      "downloading url is: https://github.com/meituan/YOLOv6/releases/download/0.4.0/yolov6s.pt, pealse make sure the version of the downloading model is correspoing to the code version!\n",
      "checkpoint yolov6s.pt downloaded and saved\n",
      "Loading checkpoint from yolov6s.pt\n",
      "\n",
      "Fusing model...\n",
      "Switch model to deploy modality.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "Results saved to runs/inference/exp\n"
     ]
    }
   ],
   "source": [
    "!python tools/infer.py --weights yolov6s.pt --source data/images/image1.jpg\n",
    "# show image\n",
    "import cv2\n",
    "img = cv2.imread('runs/inference/exp/image1.jpg')\n",
    "#cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also use torch.hub style to load the pretrained model or custom model to inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /DATA2/dse313/group14/YOLOv6/weights/yolov6n.pt\n",
      "\n",
      "Fusing model...\n",
      "/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py:836: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if param.grad is not None:\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "model_local = torch.hub.load('.', 'yolov6n', source='local')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'data/images/image1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_local\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#prediction = model_custom.predict(img_path)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m display(prediction)\n",
      "File \u001b[0;32m/DATA2/dse313/group14/YOLOv6/./hubconf.py:129\u001b[0m, in \u001b[0;36mDetector.predict\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    126\u001b[0m     img \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    128\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(img, img_src\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 129\u001b[0m out \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    130\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/DATA2/dse313/group14/YOLOv6/./hubconf.py:129\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m     img \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    128\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(img, img_src\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 129\u001b[0m out \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    130\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "prediction = model_local.predict(img_path)\n",
    "#prediction = model_custom.predict(img_path)\n",
    "display(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_local\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/DATA2/dse313/group14/YOLOv6/./hubconf.py:139\u001b[0m, in \u001b[0;36mDetector.show_predict\u001b[0;34m(self, img_path, min_score, figsize, color, linewidth)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    134\u001b[0m                  img_path,\n\u001b[1;32m    135\u001b[0m                  min_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m    136\u001b[0m                  figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m),\n\u001b[1;32m    137\u001b[0m                  color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlawngreen\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    138\u001b[0m                  linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m--> 139\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     boxes, scores, classes \u001b[38;5;241m=\u001b[39m prediction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m], prediction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m], prediction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    141\u001b[0m     visualize_detections(Image\u001b[38;5;241m.\u001b[39mopen(img_path),\n\u001b[1;32m    142\u001b[0m                          boxes, classes, scores,\n\u001b[1;32m    143\u001b[0m                          min_score\u001b[38;5;241m=\u001b[39mmin_score, figsize\u001b[38;5;241m=\u001b[39mfigsize,  color\u001b[38;5;241m=\u001b[39mcolor, linewidth\u001b[38;5;241m=\u001b[39mlinewidth\n\u001b[1;32m    144\u001b[0m                          )\n",
      "File \u001b[0;32m/DATA2/dse313/group14/YOLOv6/./hubconf.py:129\u001b[0m, in \u001b[0;36mDetector.predict\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    126\u001b[0m     img \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    128\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(img, img_src\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 129\u001b[0m out \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    130\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/DATA2/dse313/group14/YOLOv6/./hubconf.py:129\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m     img \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    128\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(img, img_src\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 129\u001b[0m out \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    130\u001b[0m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "model_local.show_predict(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoGnT0H5aGfL"
   },
   "source": [
    "# Validate\n",
    "Validate a model's accuracy on [COCO](https://cocodataset.org/#home) val or test-dev datasets. Models are downloaded automatically from the [latest YOLOv6 release](https://github.com/meituan/YOLOv6/releases). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFldWvR9aWUx"
   },
   "source": [
    "## COCO val\n",
    "Download COCO val 2017 dataset (1GB - 5000 images), and test model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8cc18eb575624cc8a3a2c235e9705d6c",
      "9ad7290d97ea44488747aae321677109",
      "2cdd2bb7d83b4f9db87ae900bdcf342d",
      "2e5401125b7248e3a081e3f57a571064",
      "74afade5e66049249b04ccdf99ac5bc3",
      "9eee5d30302b45a7b172846c58c18782",
      "84d9721bb8bd41819f5f02fdd808f35c",
      "703c9ed6ee7446d3a8efc3e20ece6dca",
      "51b7fa10e42349998974eba12fa06458",
      "4cedeada524642d6ac56a8d383ecf1ce",
      "6875d51042d54c978a81048a43268dbb"
     ]
    },
    "id": "l2SdQABjYvs6",
    "outputId": "58a26eef-e359-4a30-8e53-70fc6ef99a30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780M/780M [01:05<00:00, 12.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Download COCO val\n",
    "import torch\n",
    "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../ && rm tmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNDGzITd2Ys1",
    "outputId": "6e079132-b313-4f48-9b7f-6fbbe24bf6c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, conf_thres=0.03, config_file='', data='data/coco.yaml', device='0', do_coco_metric=True, do_pr_metric=False, eval_config_file='./configs/experiment/eval_640_repro.py', half=False, height=None, img_size=640, infer_on_rect=True, iou_thres=0.65, name='exp', plot_confusion_matrix=False, plot_curve=True, reproduce_640_eval=False, save_dir='runs/val/', shrink_size=0, specific_shape=False, task='val', verbose=False, weights='yolov6s.pt', width=None)\n",
      "Loading checkpoint from yolov6s.pt\n",
      "\n",
      "Fusing model...\n",
      "Switch model to deploy modality.\n",
      "Model Summary: Params: 18.54M, Gflops: 45.28\n",
      "img record infomation path is:../coco/images/.val2017_cache.json\n",
      "Val: Checking formats of images with 8 process(es): \n",
      "0 image(s) corrupted: 100%|██████████████| 5000/5000 [00:00<00:00, 20772.11it/s]\n",
      "Val: Checking formats of labels with 8 process(es): \n",
      "4952 label(s) found, 48 label(s) missing, 0 label(s) empty, 0 invalid label file\n",
      "Val: Final numbers of valid images: 5000/ labels: 5000. \n",
      "1.8s for dataset initialization.\n",
      "Inferencing model in val datasets.: 100%|█████| 157/157 [05:03<00:00,  1.93s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "Average pre-process time: 0.14 ms\n",
      "Average inference time: 2.90 ms\n",
      "Average NMS time: 14.53 ms\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/val/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=7.81s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=59.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=17.49s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.451\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.621\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.487\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.503\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.709\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.814\n",
      "Results saved to runs/val/exp\n"
     ]
    }
   ],
   "source": [
    "# Run yolov6x on coco val\n",
    "!python tools/eval.py --weights yolov6s.pt --data data/coco.yaml --img 640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO6NirzdeITA"
   },
   "source": [
    "# Train coco data\n",
    "conf: select config file to specify network/optimizer/hyperparameters\n",
    "\n",
    "data: prepare [COCO](http://cocodataset.org)  dataset, [YOLO format coco labes](https://github.com/meituan/YOLOv6/releases/download/0.1.0/coco2017labels.zip) and specify dataset paths in data.yaml\n",
    "\n",
    "make sure your dataset structure as fellows:\n",
    "```shell\n",
    "├── coco\n",
    "│   ├── annotations\n",
    "│   │   ├── instances_train2017.json\n",
    "│   │   └── instances_val2017.json\n",
    "│   ├── images\n",
    "│   │   ├── train2017\n",
    "│   │   └── val2017\n",
    "│   ├── labels\n",
    "│   │   ├── train2017\n",
    "│   │   ├── val2017\n",
    "│   ├── LICENSE\n",
    "│   ├── README.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hidcp3AXuCkV"
   },
   "source": [
    "## COCO datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4N3Bv84qbkP"
   },
   "outputs": [],
   "source": [
    "# Download coco datasets and need about 30mins.\n",
    "%cd ..\n",
    "%cd coco/images\n",
    "!wget http://images.cocodataset.org/zips/train2017.zip\n",
    "!wget http://images.cocodataset.org/zips/val2017.zip\n",
    "!wget http://images.cocodataset.org/zips/test2017.zip\n",
    "!unzip train2017.zip && rm train2017.zip\n",
    "!unzip val2017.zip && rm val2017.zip\n",
    "!unzip test2017.zip && rm test2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpcC_L6whcxW"
   },
   "outputs": [],
   "source": [
    "# Before running, you need to make sure you're in the YOLOv6 root directory.\n",
    "%cd ../../YOLOv6\n",
    "# Train YOLOv6s on COCO for 30 epochs\n",
    "!python tools/train.py --img 640 --batch 32 --epochs 30 --conf configs/yolov6s.py --data data/coco.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "az4pa71UuObL"
   },
   "source": [
    "## COCO128 datasets\n",
    "You need create a new file `coco128.yaml` under the folder `./data`.The details are as follows:\n",
    "\n",
    "```\n",
    "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "path: ../coco128  # dataset root dir\n",
    "train: images/train2017  # train images (relative to 'path') 128 images\n",
    "val: images/train2017  # val images (relative to 'path') 128 images\n",
    "test:  # test images (optional)\n",
    "\n",
    "# Classes\n",
    "nc: 80  # number of classes\n",
    "names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush']  # class names\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco128 = \"\"\"# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "path: ../coco128  # dataset root dir\n",
    "train: ../coco128/images/train2017  # train images 128 images\n",
    "val: ../coco128/images/train2017  # val images 128 images\n",
    "test:  # test images (optional)\n",
    "\n",
    "# Classes\n",
    "nc: 80  # number of classes\n",
    "names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush']  # class names\n",
    "\"\"\"\n",
    "\n",
    "with open('data/coco128.yaml', 'w') as f:\n",
    "  f.write(coco128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "11c01641cf274e118221dbbdc2f3afa4",
      "693b2ece47844511905ca94736c11fdd",
      "2adc2664afd5404da77a1bfede169b95",
      "7566d05f122f4281825838145d488860",
      "7b1052fd864b4e8da4941a8647ef620b",
      "fe4d2e0d47604eb08e7f4743dc0e6826",
      "5baa548a06294dd4a4a8a3330189f4cd",
      "2888af90fe40440f9f03fdcafd49da75",
      "d976baa0f3374eb4b5278e10eced2dfc",
      "11378927dc5e440080fd0300e5c301ed",
      "4cafdf53ddcc415680777bbf54399064"
     ]
    },
    "id": "qQAhslIXjjGX",
    "outputId": "5be3f8bd-1f80-4844-ee0e-aeb212ea5d35"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c01641cf274e118221dbbdc2f3afa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download coco128 datasets\n",
    "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco128.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../ && rm tmp.zip\n",
    "\n",
    "# torch.hub.download_url_to_file('https://drive.google.com/file/d/1HICm-rrsdp89GNpFbzcwksHRtDx10McK/view?usp=sharing', 'tmp.zip')\n",
    "# !unzip -q tmp.zip -d ../ && rm tmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHfmsqelioX_",
    "outputId": "6912bd42-2fcb-4b53-9b89-2efc77b38b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU for training... \n",
      "training args are: Namespace(batch_size=32, check_images=False, check_labels=False, conf_file='./configs/yolov6s.py', data_path='data/coco128.yaml', device='0', dist_url='env://', epochs=100, eval_final_only=False, eval_interval=20, gpu_count=0, heavy_eval_range=50, img_size=640, local_rank=-1, name='exp', output_dir='./runs/train', rank=-1, resume=False, save_dir='runs/train/exp', workers=8, world_size=1)\n",
      "\n",
      "Train: Checking formats of images with 2 process(es): \n",
      "\r\n",
      "  0% 0/128 [00:00<?, ?it/s]\r\n",
      "0 image(s) corrupted: 100% 128/128 [00:00<00:00, 3223.54it/s]\n",
      "Train: Checking formats of labels with 2 process(es): \n",
      "128 label(s) found, 0 label(s) missing, 2 label(s) empty, 0 invalid label files: 100% 128/128 [00:00<00:00, 3653.13it/s]\n",
      "Train: Final numbers of valid images: 128/ labels: 128. \n",
      "0.2s for dataset initialization.\n",
      "Convert to COCO format\n",
      "100% 128/128 [00:00<00:00, 32588.98it/s]\n",
      "Convert to COCO format finished. Results saved in ../coco128/annotations/instances_train2017.json\n",
      "Val: Final numbers of valid images: 128/ labels: 128. \n",
      "0.1s for dataset initialization.\n",
      "Model: Model(\n",
      "  (backbone): EfficientRep(\n",
      "    (stem): RepVGGBlock(\n",
      "      (nonlinearity): ReLU(inplace=True)\n",
      "      (se): Identity()\n",
      "      (rbr_dense): Sequential(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): Sequential(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (ERBlock_2): Sequential(\n",
      "      (0): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): Sequential(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepBlock(\n",
      "        (conv1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (block): Sequential(\n",
      "          (0): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ERBlock_3): Sequential(\n",
      "      (0): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): Sequential(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepBlock(\n",
      "        (conv1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (block): Sequential(\n",
      "          (0): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ERBlock_4): Sequential(\n",
      "      (0): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): Sequential(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepBlock(\n",
      "        (conv1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (block): Sequential(\n",
      "          (0): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ERBlock_5): Sequential(\n",
      "      (0): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): Sequential(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepBlock(\n",
      "        (conv1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (block): Sequential(\n",
      "          (0): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): Sequential(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): Sequential(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): SimSPPF(\n",
      "        (cv1): SimConv(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (cv2): SimConv(\n",
      "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (neck): RepPANNeck(\n",
      "    (Rep_p4): RepBlock(\n",
      "      (conv1): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): Sequential(\n",
      "          (conv): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Rep_p3): RepBlock(\n",
      "      (conv1): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): Sequential(\n",
      "          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Rep_n3): RepBlock(\n",
      "      (conv1): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Rep_n4): RepBlock(\n",
      "      (conv1): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): Sequential(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): Sequential(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): Sequential(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): Sequential(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reduce_layer0): SimConv(\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (upsample0): Transpose(\n",
      "      (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (reduce_layer1): SimConv(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (upsample1): Transpose(\n",
      "      (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (downsample2): SimConv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "    (downsample1): SimConv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (detect): Detect(\n",
      "    (cls_convs): ModuleList(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): ModuleList(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (cls_preds): ModuleList(\n",
      "      (0): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (reg_preds): ModuleList(\n",
      "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (obj_preds): ModuleList(\n",
      "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (stems): ModuleList(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Training start...\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "  0% 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "      0/99     4.583     3.153     11.44     1.808: 100% 4/4 [00:13<00:00,  3.28s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:01<00:00,  1.04it/s]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Epoch: 0 | mAP@0.5: 0.0 | mAP@0.50:0.95: 0.0\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      1/99     3.988     2.417     7.039     2.213: 100% 4/4 [00:03<00:00,  1.00it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      2/99     3.327     2.062     5.917     2.692: 100% 4/4 [00:03<00:00,  1.00it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      3/99     3.096      2.05     5.933     2.913: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      4/99     3.036      2.09     6.123     2.944: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      5/99     2.945     2.141     6.142     3.026: 100% 4/4 [00:03<00:00,  1.03it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      6/99     2.981     2.144     6.194     3.015: 100% 4/4 [00:03<00:00,  1.03it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      7/99     2.928     2.085     6.052     2.984: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      8/99     2.989     2.122     5.974     2.967: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "      9/99     2.916     2.101     5.909     2.979: 100% 4/4 [00:03<00:00,  1.04it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     10/99     2.977     2.141     5.939     2.909: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     11/99     3.052     2.128     5.857     2.882: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     12/99     2.887      2.08     5.903     2.938: 100% 4/4 [00:04<00:00,  1.00s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     13/99     2.914     2.188      5.94     2.902: 100% 4/4 [00:03<00:00,  1.05it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     14/99     2.872     2.132     5.783     2.912: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     15/99     2.903     2.114     5.846     2.891: 100% 4/4 [00:03<00:00,  1.04it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     16/99     2.902     2.148     5.964     2.892: 100% 4/4 [00:03<00:00,  1.03it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     17/99     2.897     2.128     5.845     2.856: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     18/99     2.904     2.119     5.845     2.814: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     19/99     2.948     2.135     5.832     2.822: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     20/99     2.977     2.138     5.777     2.792: 100% 4/4 [00:03<00:00,  1.00it/s]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:02<00:00,  1.07s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.27s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: 20 | mAP@0.5: 1.6750818591566045e-06 | mAP@0.50:0.95: 3.3892356037839674e-07\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     21/99     2.983     2.114     5.881     2.747: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     22/99     2.968     2.096     5.737     2.809: 100% 4/4 [00:03<00:00,  1.00it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     23/99     2.983     2.115     5.701     2.802: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     24/99     2.917     2.066     5.781       2.8: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     25/99     2.861     2.095     5.682     2.829: 100% 4/4 [00:03<00:00,  1.00it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     26/99      2.97     2.137     5.713     2.772: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     27/99     3.011     2.111     5.732     2.768: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     28/99     2.951     2.126     5.782     2.765: 100% 4/4 [00:03<00:00,  1.03it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     29/99     2.896     2.122     5.653     2.742: 100% 4/4 [00:03<00:00,  1.04it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     30/99     2.924     2.167     5.641      2.77: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     31/99     2.933     2.152     5.604     2.773: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     32/99     2.849     2.098      5.67     2.849: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     33/99     2.939      2.15     5.628     2.768: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     34/99      2.92     2.104     5.545     2.721: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     35/99     2.933     2.129     5.512     2.737: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     36/99     2.918     2.073     5.513      2.74: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     37/99     3.028     2.135     5.644     2.779: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     38/99     2.993     2.112     5.544     2.738: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     39/99     2.926     2.106     5.491     2.759: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     40/99     2.934     2.109     5.577     2.799: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:03<00:00,  1.95s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.82s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      "Epoch: 40 | mAP@0.5: 3.026791640822253e-05 | mAP@0.50:0.95: 6.039800579863439e-06\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     41/99     2.914     2.091     5.657     2.752: 100% 4/4 [00:04<00:00,  1.00s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     42/99     2.838     2.117     5.409     2.809: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     43/99     2.876     2.136     5.486      2.79: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     44/99     2.885     2.117     5.537     2.808: 100% 4/4 [00:03<00:00,  1.00it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     45/99     2.853     2.126     5.489     2.687: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     46/99     2.899     2.088     5.509     2.721: 100% 4/4 [00:03<00:00,  1.04it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     47/99     2.898     2.131      5.45     2.737: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     48/99     2.906     2.083     5.451     2.764: 100% 4/4 [00:03<00:00,  1.02it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     49/99     2.821     2.041     5.355     2.744: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     50/99     2.965     2.119     5.578     2.727: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.02s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.93s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "Epoch: 50 | mAP@0.5: 0.0011824408042347809 | mAP@0.50:0.95: 0.0006655534080554066\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     51/99     2.851     2.088     5.553     2.752: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.00s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      "Epoch: 51 | mAP@0.5: 0.0009480009060269342 | mAP@0.50:0.95: 0.00032895331614389605\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     52/99     2.871     2.043     5.434     2.804: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:03<00:00,  1.98s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 52 | mAP@0.5: 0.0031166655823601013 | mAP@0.50:0.95: 0.001677834178007029\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     53/99      2.88     2.068     5.504     2.734: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:03<00:00,  1.99s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      "Epoch: 53 | mAP@0.5: 0.0022269664066922627 | mAP@0.50:0.95: 0.0011167281467850919\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     54/99     2.888     2.019     5.376     2.783: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.02s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 54 | mAP@0.5: 0.0010945365556061782 | mAP@0.50:0.95: 0.0002490448763870229\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     55/99      2.97     2.088     5.397     2.722: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.10s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      "Epoch: 55 | mAP@0.5: 0.005153651332037936 | mAP@0.50:0.95: 0.0016851377773941941\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     56/99     2.882     2.083     5.334     2.711: 100% 4/4 [00:04<00:00,  1.07s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.10s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.40s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.94s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 56 | mAP@0.5: 0.0009605207151018805 | mAP@0.50:0.95: 0.00022679096614965465\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     57/99      2.82     2.024     5.357     2.727: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.18s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.92s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 57 | mAP@0.5: 0.0036119729632591684 | mAP@0.50:0.95: 0.0008314271402840496\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     58/99     2.812     2.039     5.328     2.699: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.11s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.42s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
      "Epoch: 58 | mAP@0.5: 0.001963490873583836 | mAP@0.50:0.95: 0.0004543273581016357\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     59/99     2.778     2.002     5.236     2.708: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.12s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.87s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      "Epoch: 59 | mAP@0.5: 0.0010819224987984467 | mAP@0.50:0.95: 0.000243906737345905\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     60/99     2.854     2.046     5.339     2.733: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.10s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      "Epoch: 60 | mAP@0.5: 0.0006596587362550893 | mAP@0.50:0.95: 0.00023252221958629067\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     61/99     2.809     2.055     5.321     2.677: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.13s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      "Epoch: 61 | mAP@0.5: 0.0004019507666707206 | mAP@0.50:0.95: 9.430218270547424e-05\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     62/99     2.788      2.07     5.374     2.751: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.07s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.40s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.86s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      "Epoch: 62 | mAP@0.5: 0.00035239314273155113 | mAP@0.50:0.95: 0.00011626138925332593\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     63/99     2.817     2.013     5.315     2.706: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.16s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 63 | mAP@0.5: 0.004203667127063244 | mAP@0.50:0.95: 0.0012639422635148776\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     64/99     2.817     2.014      5.31     2.755: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.09s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
      "Epoch: 64 | mAP@0.5: 0.0008575287529128892 | mAP@0.50:0.95: 0.000191750774372226\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     65/99      2.83     2.015     5.352      2.78: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.02s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
      "Epoch: 65 | mAP@0.5: 0.0017627231047534784 | mAP@0.50:0.95: 0.0012750007112268785\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     66/99     2.837     2.025     5.314     2.778: 100% 4/4 [00:03<00:00,  1.00it/s]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.12s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.41s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.93s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      "Epoch: 66 | mAP@0.5: 0.0033239425757449724 | mAP@0.50:0.95: 0.002065487064492566\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     67/99     2.813     2.015     5.284     2.759: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.22s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.94s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
      "Epoch: 67 | mAP@0.5: 0.004636293584747839 | mAP@0.50:0.95: 0.003096991523250025\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     68/99     2.794     2.029     5.313     2.773: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.05s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.92s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 68 | mAP@0.5: 0.0012790427934887515 | mAP@0.50:0.95: 0.0004166938502445351\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     69/99     2.797     2.022     5.254     2.751: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.26s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\n",
      "Epoch: 69 | mAP@0.5: 0.002834136481615038 | mAP@0.50:0.95: 0.0005070867255685134\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     70/99     2.818      2.02     5.277     2.751: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.14s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
      "Epoch: 70 | mAP@0.5: 0.0032584690726534687 | mAP@0.50:0.95: 0.0010810245310215571\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     71/99     2.775      2.01     5.242      2.76: 100% 4/4 [00:04<00:00,  1.04s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.07s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.86s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
      "Epoch: 71 | mAP@0.5: 0.0010575553057165944 | mAP@0.50:0.95: 0.00028138197011783815\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     72/99     2.676     1.978     5.262     2.748: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.14s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.87s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      "Epoch: 72 | mAP@0.5: 0.0021715072697373974 | mAP@0.50:0.95: 0.0008307456030174317\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     73/99     2.741     2.031     5.255     2.663: 100% 4/4 [00:04<00:00,  1.05s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.08s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      "Epoch: 73 | mAP@0.5: 0.0007658497298332965 | mAP@0.50:0.95: 0.0002667844203444723\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     74/99     2.737     2.016     5.202      2.71: 100% 4/4 [00:04<00:00,  1.07s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.07s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.87s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      "Epoch: 74 | mAP@0.5: 0.002804220327313575 | mAP@0.50:0.95: 0.0008573694770221916\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     75/99     2.726     1.995     5.193     2.696: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.15s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
      "Epoch: 75 | mAP@0.5: 0.002547520930802475 | mAP@0.50:0.95: 0.0008915343566093971\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     76/99     2.773     2.006     5.175     2.764: 100% 4/4 [00:04<00:00,  1.06s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.10s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 76 | mAP@0.5: 0.0018508136034399872 | mAP@0.50:0.95: 0.0006714676475958497\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     77/99     2.756     1.997     5.192     2.614: 100% 4/4 [00:04<00:00,  1.05s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.12s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 77 | mAP@0.5: 0.0026893725562022364 | mAP@0.50:0.95: 0.0009231173957208621\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     78/99     2.708     1.974     5.109      2.68: 100% 4/4 [00:04<00:00,  1.07s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.08s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.40s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 78 | mAP@0.5: 0.003849575369068528 | mAP@0.50:0.95: 0.0011330416176916509\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     79/99     2.773     1.989     5.156     2.696: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.18s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      "Epoch: 79 | mAP@0.5: 0.001792239219006599 | mAP@0.50:0.95: 0.0007388597488008516\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     80/99      2.71     1.989     5.217     2.788: 100% 4/4 [00:04<00:00,  1.04s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.10s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 80 | mAP@0.5: 0.0024191482916546114 | mAP@0.50:0.95: 0.0009550677904573214\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     81/99     2.714     1.992     5.198     2.704: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.21s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 81 | mAP@0.5: 0.002824566532320574 | mAP@0.50:0.95: 0.0009378720988676307\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     82/99     2.746     2.002      5.25     2.774: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.93s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      "Epoch: 82 | mAP@0.5: 0.0028046325531085694 | mAP@0.50:0.95: 0.0007749166276927232\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     83/99     2.826     2.009     5.239     2.749: 100% 4/4 [00:04<00:00,  1.04s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.17s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "Epoch: 83 | mAP@0.5: 0.004983682488135256 | mAP@0.50:0.95: 0.00187192184023182\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     84/99     2.745     1.973      5.17     2.728: 100% 4/4 [00:04<00:00,  1.04s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.06s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 84 | mAP@0.5: 0.003129905903839608 | mAP@0.50:0.95: 0.0009654394720239379\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     85/99     2.751     1.982     5.208     2.768: 100% 4/4 [00:04<00:00,  1.04s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.12s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.88s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.37s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 85 | mAP@0.5: 0.002559613519039063 | mAP@0.50:0.95: 0.0009747811853783635\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     86/99     2.738     1.948      5.22     2.755: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.14s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 86 | mAP@0.5: 0.004146007623652573 | mAP@0.50:0.95: 0.0013604230654060594\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     87/99     2.779     1.973     5.232     2.777: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.13s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      "Epoch: 87 | mAP@0.5: 0.003346422762302339 | mAP@0.50:0.95: 0.0008979883867943451\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     88/99     2.821     2.002     5.263     2.698: 100% 4/4 [00:04<00:00,  1.05s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.11s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.07s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 88 | mAP@0.5: 0.002818659051814291 | mAP@0.50:0.95: 0.0007799934175857097\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     89/99     2.748     1.965     5.223     2.758: 100% 4/4 [00:03<00:00,  1.01it/s]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.09s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.93s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      "Epoch: 89 | mAP@0.5: 0.002464946631345105 | mAP@0.50:0.95: 0.0006882788522437844\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     90/99     2.722     1.941     5.105     2.718: 100% 4/4 [00:04<00:00,  1.05s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.16s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.92s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 90 | mAP@0.5: 0.002959344475120238 | mAP@0.50:0.95: 0.0007900364706187752\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     91/99       2.7     1.958     4.979     2.665: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.12s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.92s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 91 | mAP@0.5: 0.003063822019051619 | mAP@0.50:0.95: 0.0009358929419405853\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     92/99     2.702     1.979     5.136      2.72: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "Epoch: 92 | mAP@0.5: 0.003895490176460533 | mAP@0.50:0.95: 0.0011654527267505052\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     93/99     2.673     1.968     5.219     2.756: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.19s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "Epoch: 93 | mAP@0.5: 0.0037510587788985895 | mAP@0.50:0.95: 0.0010245456003092454\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     94/99     2.663     1.992     5.112     2.712: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.08s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.40s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "Epoch: 94 | mAP@0.5: 0.0036380662329819277 | mAP@0.50:0.95: 0.0009167687056423719\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     95/99     2.745     1.995     5.145     2.692: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.17s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "Epoch: 95 | mAP@0.5: 0.0026693887157190127 | mAP@0.50:0.95: 0.0007715339972043266\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     96/99     2.757     2.001     5.205     2.714: 100% 4/4 [00:04<00:00,  1.01s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.15s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.90s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.39s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      "Epoch: 96 | mAP@0.5: 0.003497939244817715 | mAP@0.50:0.95: 0.000997181915488942\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     97/99      2.76     2.022     5.198     2.734: 100% 4/4 [00:04<00:00,  1.02s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.18s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      "Epoch: 97 | mAP@0.5: 0.0034934967705090407 | mAP@0.50:0.95: 0.001182990098132355\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     98/99     2.744     1.949     5.143     2.648: 100% 4/4 [00:04<00:00,  1.03s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.17s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.41s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      "Epoch: 98 | mAP@0.5: 0.003286477028324472 | mAP@0.50:0.95: 0.0011104174392147258\n",
      "\n",
      "     Epoch  iou_loss   l1_loss  obj_loss  cls_loss\n",
      "     99/99     2.723     1.984     5.113     2.729: 100% 4/4 [00:04<00:00,  1.04s/it]\n",
      "Inferencing model in val datasets.: 100% 2/2 [00:04<00:00,  2.14s/it]\n",
      "\n",
      "Evaluating speed.\n",
      "\n",
      "Evaluating mAP by pycocotools.\n",
      "Saving runs/train/exp/predictions.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.91s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.38s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      "Epoch: 99 | mAP@0.5: 0.003454596142400072 | mAP@0.50:0.95: 0.001096205320071562\n",
      "\n",
      "Training completed in 0.230 hours.\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv6s on COCO128 for 100 epochs\n",
    "!python tools/train.py --img 640 --batch 32 --epochs 100 --data data/coco128.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFBCgHq_gDmB"
   },
   "outputs": [],
   "source": [
    "# Tensorboard  (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwPPL3Tc0aBF"
   },
   "source": [
    "# Train Custom Data\n",
    "This guidence explains how to train your own custom data with YOLOv6 (take fine-tuning YOLOv6-s model for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JtfQNUX0-hZ"
   },
   "source": [
    "## Prepare your own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMPZV_5F0eGQ"
   },
   "source": [
    "**Step 1** Prepare your own dataset with images. For labeling images, you can use tools like [Labelme](https://github.com/wkentaro/labelme).\n",
    "\n",
    "**Step 2** Generate label files in YOLO format.\n",
    "\n",
    "One image corresponds to one label file, and the label format example is presented as below.\n",
    "\n",
    "```json\n",
    "# class_id center_x center_y bbox_width bbox_height\n",
    "0 0.300926 0.617063 0.601852 0.765873\n",
    "1 0.575 0.319531 0.4 0.551562\n",
    "```\n",
    "\n",
    "- Each row represents one object.\n",
    "- Class id starts from `0`.\n",
    "- Boundingbox coordinates must be in normalized `xywh` format (from 0 - 1). If your boxes are in pixels, divide `center_x` and `bbox_width` by image width, and `center_y` and `bbox_height` by image height.\n",
    "\n",
    "**Step 3** Organize directories.\n",
    "\n",
    "Organize your directory of custom dataset as follows:\n",
    "\n",
    "```shell\n",
    "custom_dataset\n",
    "├── images\n",
    "│   ├── train\n",
    "│   │   ├── train0.jpg\n",
    "│   │   └── train1.jpg\n",
    "│   ├── val\n",
    "│   │   ├── val0.jpg\n",
    "│   │   └── val1.jpg\n",
    "│   └── test\n",
    "│       ├── test0.jpg\n",
    "│       └── test1.jpg\n",
    "└── labels\n",
    "    ├── train\n",
    "    │   ├── train0.txt\n",
    "    │   └── train1.txt\n",
    "    ├── val\n",
    "    │   ├── val0.txt\n",
    "    │   └── val1.txt\n",
    "    └── test\n",
    "        ├── test0.txt\n",
    "        └── test1.txt\n",
    "```\n",
    "\n",
    "**Step 4** Create `dataset.yaml` in `$YOLOv6_DIR/data`.\n",
    "\n",
    "```yaml\n",
    "# Please insure that your custom_dataset are put in same parent dir with YOLOv6_DIR\n",
    "train: ../custom_dataset/images/train # train images\n",
    "val: ../custom_dataset/images/val # val images\n",
    "test: ../custom_dataset/images/test # test images (optional)\n",
    "\n",
    "# whether it is coco dataset, only coco dataset should be set to True.\n",
    "is_coco: False\n",
    "\n",
    "# Classes\n",
    "nc: 20  # number of classes\n",
    "names: ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',\n",
    "        'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']  # class names\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lthBb8t1ETU"
   },
   "source": [
    "## Create a config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqAuhsaQ1J6L"
   },
   "source": [
    "\n",
    "We use a config file to specify the network structure and training setting, including  optimizer and data augmentation hyperparameters.\n",
    "\n",
    "If you create a new config file, please put it under the configs directory.\n",
    "Or just use the provided config file in `$YOLOV6_HOME/configs/*_finetune.py`.\n",
    "\n",
    "```python\n",
    "## YOLOv6s Model config file\n",
    "model = dict(\n",
    "    type='YOLOv6s',\n",
    "    pretrained='./weights/yolov6s.pt', # download pretrain model from YOLOv6 github if use pretrained model\n",
    "    depth_multiple = 0.33,\n",
    "    width_multiple = 0.50,\n",
    "    ...\n",
    ")\n",
    "solver=dict(\n",
    "    optim='SGD',\n",
    "    lr_scheduler='Cosine',\n",
    "    ...\n",
    ")\n",
    "\n",
    "data_aug = dict(\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlaEpwIh1b9a"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LjyNAANP1o2p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "2\n",
      "2\n",
      "Using 1 GPU for training... \n",
      "training args are: Namespace(batch_size=256, bs_per_gpu=32, cache_ram=False, calib=False, check_images=False, check_labels=False, conf_file='configs/yolov6s_finetune.py', data_path='data/dataset.yaml', device='2', dist_url='env://', distill=False, distill_feat=False, epochs=400, eval_final_only=False, eval_interval=20, fuse_ab=False, gpu_count=3, heavy_eval_range=50, height=None, img_size=640, local_rank=-1, name='exp', output_dir='./runs/train', quant=False, rank=-1, rect=False, resume=False, save_ckpt_on_last_n_epoch=-1, save_dir='runs/train/exp20', specific_shape=False, stop_aug_last_n_epoch=15, teacher_model_path=None, temperature=20, width=None, workers=8, world_size=1, write_trainbatch_tb=False)\n",
      "\n",
      "Loading state_dict from weights/yolov6s.pt for fine-tuning...\n",
      "Model: Model(\n",
      "  (backbone): EfficientRep(\n",
      "    (stem): RepVGGBlock(\n",
      "      (nonlinearity): ReLU(inplace=True)\n",
      "      (se): Identity()\n",
      "      (rbr_dense): ConvModule(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (rbr_1x1): ConvModule(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (ERBlock_2): Sequential(\n",
      "      (0): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): ConvModule(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): ConvModule(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepBlock(\n",
      "        (conv1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (block): Sequential(\n",
      "          (0): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ERBlock_3): Sequential(\n",
      "      (0): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): ConvModule(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): ConvModule(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepBlock(\n",
      "        (conv1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (block): Sequential(\n",
      "          (0): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ERBlock_4): Sequential(\n",
      "      (0): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): ConvModule(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): ConvModule(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepBlock(\n",
      "        (conv1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (block): Sequential(\n",
      "          (0): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (4): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ERBlock_5): Sequential(\n",
      "      (0): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_dense): ConvModule(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): ConvModule(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): RepBlock(\n",
      "        (conv1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (block): Sequential(\n",
      "          (0): RepVGGBlock(\n",
      "            (nonlinearity): ReLU(inplace=True)\n",
      "            (se): Identity()\n",
      "            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (rbr_dense): ConvModule(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (rbr_1x1): ConvModule(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): SimCSPSPPF(\n",
      "        (cspsppf): CSPSPPFModule(\n",
      "          (cv1): ConvBNReLU(\n",
      "            (block): ConvModule(\n",
      "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (cv2): ConvBNReLU(\n",
      "            (block): ConvModule(\n",
      "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (cv3): ConvBNReLU(\n",
      "            (block): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (cv4): ConvBNReLU(\n",
      "            (block): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "          (cv5): ConvBNReLU(\n",
      "            (block): ConvModule(\n",
      "              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (cv6): ConvBNReLU(\n",
      "            (block): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (cv7): ConvBNReLU(\n",
      "            (block): ConvModule(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (neck): RepBiFPANNeck(\n",
      "    (reduce_layer0): ConvBNReLU(\n",
      "      (block): ConvModule(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (Bifusion0): BiFusion(\n",
      "      (cv1): ConvBNReLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cv2): ConvBNReLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cv3): ConvBNReLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (upsample): Transpose(\n",
      "        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (downsample): ConvBNReLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Rep_p4): RepBlock(\n",
      "      (conv1): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reduce_layer1): ConvBNReLU(\n",
      "      (block): ConvModule(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (Bifusion1): BiFusion(\n",
      "      (cv1): ConvBNReLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cv2): ConvBNReLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cv3): ConvBNReLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (upsample): Transpose(\n",
      "        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (downsample): ConvBNReLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Rep_p3): RepBlock(\n",
      "      (conv1): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): ConvModule(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): ConvModule(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (downsample2): ConvBNReLU(\n",
      "      (block): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (Rep_n3): RepBlock(\n",
      "      (conv1): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (downsample1): ConvBNReLU(\n",
      "      (block): ConvModule(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (Rep_n4): RepBlock(\n",
      "      (conv1): RepVGGBlock(\n",
      "        (nonlinearity): ReLU(inplace=True)\n",
      "        (se): Identity()\n",
      "        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (rbr_dense): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (rbr_1x1): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (block): Sequential(\n",
      "        (0): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): RepVGGBlock(\n",
      "          (nonlinearity): ReLU(inplace=True)\n",
      "          (se): Identity()\n",
      "          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (rbr_dense): ConvModule(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (rbr_1x1): ConvModule(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (detect): Detect(\n",
      "    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (stems): ModuleList(\n",
      "      (0): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls_convs): ModuleList(\n",
      "      (0): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reg_convs): ModuleList(\n",
      "      (0): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): ConvBNSiLU(\n",
      "        (block): ConvModule(\n",
      "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls_preds): ModuleList(\n",
      "      (0): Conv2d(64, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(128, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (reg_preds): ModuleList(\n",
      "      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "img record infomation path is:../custom_dataset/images/.train_cache.json\n",
      "Train: Final numbers of valid images: 6690/ labels: 6690. \n",
      "0.3s for dataset initialization.\n",
      "img record infomation path is:../custom_dataset/images/.valid_cache.json\n",
      "Convert to COCO format\n",
      "100%|████████████████████████████████████| 1912/1912 [00:00<00:00, 49587.01it/s]\n",
      "Convert to COCO format finished. Resutls saved in ../custom_dataset/annotations/instances_valid.json\n",
      "Val: Final numbers of valid images: 1912/ labels: 1912. \n",
      "0.6s for dataset initialization.\n",
      "WARNING: DP not recommended, use DDP instead.\n",
      "\n",
      "/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "Training start...\n",
      "\n",
      "     Epoch        lr  iou_loss  dfl_loss  cls_loss\n",
      "  0%|          | 0/27 [00:22<?, ?it/s]                                          \n",
      "ERROR in training steps.\n",
      "ERROR in training loop or eval/save model.\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/train.py\", line 147, in <module>\n",
      "    main(args)\n",
      "  File \"tools/train.py\", line 134, in main\n",
      "    trainer.train()\n",
      "  File \"/DATA2/dse313/group14/YOLOv6/yolov6/core/engine.py\", line 121, in train\n",
      "    self.train_one_epoch(self.epoch)\n",
      "  File \"/DATA2/dse313/group14/YOLOv6/yolov6/core/engine.py\", line 135, in train_one_epoch\n",
      "    self.train_in_steps(epoch_num, self.step)\n",
      "  File \"/DATA2/dse313/group14/YOLOv6/yolov6/core/engine.py\", line 152, in train_in_steps\n",
      "    preds, s_featmaps = self.model(images)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 108, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "torch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/YOLOv6/yolov6/models/yolo.py\", line 36, in forward\n",
      "    x = self.neck(x)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/YOLOv6/yolov6/models/reppan.py\", line 220, in forward\n",
      "    f_concat_layer0 = self.Bifusion0([fpn_out0, x1, x2])\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/YOLOv6/yolov6/layers/common.py\", line 715, in forward\n",
      "    x0 = self.upsample(x[0])\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/YOLOv6/yolov6/layers/common.py\", line 194, in forward\n",
      "    return self.upsample_transpose(x)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/DATA2/dse313/group14/virtual_env/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 952, in forward\n",
      "    return F.conv_transpose2d(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 34.81 MiB is free. Process 1878357 has 6.06 GiB memory in use. Process 225498 has 416.00 MiB memory in use. Process 888349 has 1.94 GiB memory in use. Process 890029 has 1.90 GiB memory in use. Process 968834 has 3.27 GiB memory in use. Process 1088403 has 2.62 GiB memory in use. Process 2472901 has 1.17 GiB memory in use. Process 2514546 has 1.09 GiB memory in use. Including non-PyTorch memory, this process has 10.84 GiB memory in use. Process 2565917 has 9.95 GiB memory in use. Of the allocated memory 9.94 GiB is allocated by PyTorch, and 117.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.cuda\n",
    "\n",
    "# print(torch.cuda.device_count())\n",
    "# print(torch.cuda.current_device())\n",
    "!python tools/train.py --batch 256 --conf configs/yolov6s_finetune.py --data data/dataset.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEa2QWm_nT6S"
   },
   "source": [
    "# Test Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9Tb5dlomxch",
    "outputId": "739e27b9-3197-4f84-ba35-85bc5eff4a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, conf_thres=0.001, data='data/coco128.yaml', device='0', half=False, img_size=640, iou_thres=0.65, name='exp', save_dir='runs/val/', task='speed', weights='yolov6s.pt')\n",
      "Loading checkpoint from yolov6s.pt\n",
      "\n",
      "Fusing model...\n",
      "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Switch model to deploy modality.\n",
      "Model Summary: Params: 17.22M, Gflops: 44.19\n",
      "Speed: Checking formats of labels with 2 process(es): \n",
      "128 label(s) found, 0 label(s) missing, 2 label(s) empty, 0 invalid label files: 100% 128/128 [00:00<00:00, 2462.39it/s]\n",
      "Speed: Final numbers of valid images: 128/ labels: 128. \n",
      "0.2s for dataset initialization.\n",
      "Inferencing model in val datasets.: 100% 4/4 [00:01<00:00,  2.24it/s]\n",
      "\n",
      "Evaluating speed.\n",
      "Average pre-process time: 0.16 ms\n",
      "Average inference time: 6.90 ms\n",
      "Average NMS time: 1.36 ms\n",
      "\n",
      "Evaluating mAP by pycocotools.\n"
     ]
    }
   ],
   "source": [
    "!python tools/eval.py --data data/coco128.yaml --batch 32 --weights yolov6s.pt --task speed"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07dd33f907684614ba2e5bfadd48ff7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_21a7574d0f3e4638880e61be9973475e",
       "IPY_MODEL_0f610d79cba74702a5f0dca9712f6cdc",
       "IPY_MODEL_0f4c5a98a3b84e3e9231b58c93e5959a"
      ],
      "layout": "IPY_MODEL_a4ddf9969ed4474dad94e0a0d71b6239"
     }
    },
    "0f4c5a98a3b84e3e9231b58c93e5959a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdad0e7d90954729a4a8fe10a7884f04",
      "placeholder": "​",
      "style": "IPY_MODEL_8c6dc1b0b5014feb9c9ad7c2442e1727",
      "value": " 36.3M/36.3M [00:04&lt;00:00, 6.91MB/s]"
     }
    },
    "0f610d79cba74702a5f0dca9712f6cdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e272cd27f3ff47ad98d6b011e07ab66d",
      "max": 38101272,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_109524f358894009b0d3dfb1977e18b9",
      "value": 38101272
     }
    },
    "109524f358894009b0d3dfb1977e18b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "11378927dc5e440080fd0300e5c301ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11c01641cf274e118221dbbdc2f3afa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_693b2ece47844511905ca94736c11fdd",
       "IPY_MODEL_2adc2664afd5404da77a1bfede169b95",
       "IPY_MODEL_7566d05f122f4281825838145d488860"
      ],
      "layout": "IPY_MODEL_7b1052fd864b4e8da4941a8647ef620b"
     }
    },
    "21a7574d0f3e4638880e61be9973475e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f31b5c163fe4410d985d6e66767e0524",
      "placeholder": "​",
      "style": "IPY_MODEL_dbf3237c84a0431e90508105e56395c3",
      "value": "100%"
     }
    },
    "2888af90fe40440f9f03fdcafd49da75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2adc2664afd5404da77a1bfede169b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2888af90fe40440f9f03fdcafd49da75",
      "max": 6984509,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d976baa0f3374eb4b5278e10eced2dfc",
      "value": 6984509
     }
    },
    "2cdd2bb7d83b4f9db87ae900bdcf342d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_703c9ed6ee7446d3a8efc3e20ece6dca",
      "max": 818322941,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51b7fa10e42349998974eba12fa06458",
      "value": 818322941
     }
    },
    "2e5401125b7248e3a081e3f57a571064": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cedeada524642d6ac56a8d383ecf1ce",
      "placeholder": "​",
      "style": "IPY_MODEL_6875d51042d54c978a81048a43268dbb",
      "value": " 780M/780M [01:56&lt;00:00, 15.9MB/s]"
     }
    },
    "4cafdf53ddcc415680777bbf54399064": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cedeada524642d6ac56a8d383ecf1ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51b7fa10e42349998974eba12fa06458": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5baa548a06294dd4a4a8a3330189f4cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6875d51042d54c978a81048a43268dbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "693b2ece47844511905ca94736c11fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe4d2e0d47604eb08e7f4743dc0e6826",
      "placeholder": "​",
      "style": "IPY_MODEL_5baa548a06294dd4a4a8a3330189f4cd",
      "value": "100%"
     }
    },
    "703c9ed6ee7446d3a8efc3e20ece6dca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74afade5e66049249b04ccdf99ac5bc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7566d05f122f4281825838145d488860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11378927dc5e440080fd0300e5c301ed",
      "placeholder": "​",
      "style": "IPY_MODEL_4cafdf53ddcc415680777bbf54399064",
      "value": " 6.66M/6.66M [00:00&lt;00:00, 9.35MB/s]"
     }
    },
    "7b1052fd864b4e8da4941a8647ef620b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84d9721bb8bd41819f5f02fdd808f35c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c6dc1b0b5014feb9c9ad7c2442e1727": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8cc18eb575624cc8a3a2c235e9705d6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ad7290d97ea44488747aae321677109",
       "IPY_MODEL_2cdd2bb7d83b4f9db87ae900bdcf342d",
       "IPY_MODEL_2e5401125b7248e3a081e3f57a571064"
      ],
      "layout": "IPY_MODEL_74afade5e66049249b04ccdf99ac5bc3"
     }
    },
    "9ad7290d97ea44488747aae321677109": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eee5d30302b45a7b172846c58c18782",
      "placeholder": "​",
      "style": "IPY_MODEL_84d9721bb8bd41819f5f02fdd808f35c",
      "value": "100%"
     }
    },
    "9eee5d30302b45a7b172846c58c18782": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4ddf9969ed4474dad94e0a0d71b6239": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdad0e7d90954729a4a8fe10a7884f04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d976baa0f3374eb4b5278e10eced2dfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dbf3237c84a0431e90508105e56395c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e272cd27f3ff47ad98d6b011e07ab66d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f31b5c163fe4410d985d6e66767e0524": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe4d2e0d47604eb08e7f4743dc0e6826": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
